{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Vodafone users' fluxes\n",
    "\n",
    "The study of the flux of people inside urban areas is of paramount importance to achieve an optimal understanding of emerging critical issues in the local mobility, and to explore areas of potential improvements in the infrastructures and local transports.\n",
    "\n",
    "The mobility of users within and toward Padova has been monitored using the data provided by the Vodafone mobile carrier, which provides the information based on the users' connections to the network cells.\n",
    "The data provided by the carrier encompasses the monitoring of the users connected to the Vodafone network in Padova in a four-month period from February to May of 2018.\n",
    "\n",
    "To provide statistical insights on the number and the flow of users, the data is aggregated based on the origin and movements of the users by averaging the number of connections during the time of the monitoring.\n",
    "\n",
    "To further avoid privacy violation issues, all observations with less than 30 units (e.g. day-areas for which $<$ 30 users have contributed) have been discarded and/or merged into dedicated categories (indicated with \"altro\", or \"other\").\n",
    "\n",
    "\n",
    "## Datasets \n",
    "\n",
    "The data is provided in `.csv` files.\n",
    "\n",
    "* __day_od.csv__: table of the origins and destinations of the users averaged by the day of the week. The data is provided with details of the month, type of user (resident in Padova/Italian visitor/foreign visitor), country of provenance, together with the province and comune of the user (if available).\n",
    "* __distinct_users_day.csv__: table of the number of distinct users by origin. The data is provided with details of the month, type of user (resident in Padova/Italian visitor/foreign visitor), country of provenance, together with the province and comune of the user (if available).\n",
    "\n",
    "The information is stored in the fields according to the following scheme: \n",
    "\n",
    "- __MONTH__: month analyzed\n",
    "- __DOW__: day analyzed\n",
    "- __ORIGIN__: users' origin area (do not consider this field)\n",
    "- __DESTINATION__: users' destination area (do not consider this field)\n",
    "- __CUST_CLASS__: user type (resident / Italian visitor / foreigner visitor)\n",
    "- __COD_COUNTRY__: users' country code (e.g. 222=Italy)\n",
    "- __COD_PRO__: users' province code (e.g. 12=Varese) \n",
    "- __PRO_COM__: users' comune code (e.g. 12026=Busto Arsizio)\n",
    "- __FLOW__: number of movements for given date-time (with a minimum of 30 users)\n",
    "- __VISITORS__: overall number of users \n",
    "\n",
    "Together with the data files, three lookup-tables are provided to allow matching the Italian institute of STATistics (ISTAT) country, province and comune codes to the actual names.\n",
    "\n",
    "* __codici_istat_comune.csv__: lookup file containing the mapping between _comune_ ISTAT code-names\n",
    "* __codici_istat_provincia.csv__: lookup file containing the mapping between _province_ ISTAT code-names\n",
    "* __codici_nazioni.csv__: lookup file containing mapping the _country_ code to its name\n",
    "\n",
    "Additional information, useful for the study of the flow of users, as the number of inhabitants of each province and the distance between Padova and all other Italian provinces can be extracted based on the data collected by the ISTAT:\n",
    "\n",
    "   - English: https://www.istat.it/en/analysis-and-products/databases, Italian: https://www.istat.it/it/dati-analisi-e-prodotti/banche-dati\n",
    "   \n",
    "   - English/Italian: https://www.istat.it/en/archive/157423, Italian: https://www.istat.it/it/archivio/157423\n",
    "   \n",
    "   - `.zip` package containing the distances between comuni in Veneto region: http://www.istat.it/storage/cartografia/matrici_distanze/Veneto.zip\n",
    "\n",
    "If deemed useful, the open repository [https://github.com/openpolis/geojson-italy](https://github.com/openpolis/geojson-italy) contains a `.json` file with the geographical coordinates of the provences and comuni of Italy.\n",
    "\n",
    "\n",
    "## Assignments\n",
    "\n",
    "1. Data preparation: the csv files are originated from different sources, hence resulting in differences in the encoding and end-of-lines that have to be taken into account in the data preparation phase. Make sure each .csv file is properly interpreted.\n",
    "\n",
    "   1.1 Ranking of visitors from foreign countries: based on the number of total visitors per each country, create a ranked plot of the first 20 countries with the most visitors\n",
    "   \n",
    "   1.2 Ranking of Italian visitors by province, weighted by the number of inhabitants: based on the number of total visitors per Italian province, create a ranked plot of the first 20 provinces with the most visitors taking into account the number of inhabitants.\n",
    "\n",
    "\n",
    "2. Study of the visitors' fluxes: you are asked to provide indications on how to invest resources to improve the mobility towards Padova. Consider the three main directions of visitors and commuters getting to Padova through the main highways (from south, A13 towards Bologna-Roma; from west, A4 towards Milano-Torino; from north-east, A4 towards Venice-Trieste). Evaluate which of the three directions has to be prioritized.\n",
    "\n",
    "   2.1 Consider a simplified case involving only the mid-range mobility, based on the number of visitors/commuters from the nearby regions only\n",
    "   \n",
    "   2.2 Consider the provinces located on the three directions that are mostly contributing to the flow of weekend visitors and working daily commuters by performing a more detailed study of the fluxes based on the day of the week. Use the data available to provide what you believe is the best possible answer.\n",
    "\n",
    "\n",
    "3. Plot the distribution of the number of visitors by the distance of the province of origin. Determine which kind of function should be used to describe the distribution.\n",
    "\n",
    "   3.1 Assuming an analytic form can be used to describe the trend, create a regression or a fit to estimate the expected number of visitors by the distance of the province of origin and the corresponding uncertainties. Illustrate the difference between the resulting regression with respect to the numbers provided by the Vodafone monitoring, and highlight the five most striking discrepancies from the expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet #Used to detect the encoding of the CSV files\n",
    "import codecs  #Used to read the CSV UTF-16\n",
    "import io      #Used to write the CSV ISO-8859-1\n",
    "import pandas as pd #Used to store data into dataframes\n",
    "import matplotlib.pyplot as plt #Used to represent data\n",
    "import numpy as np #Used to rename the column of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of csv files\n",
    "filename_codici_istat_comuni = \"data\\codici_istat_comune.csv\"\n",
    "filename_codici_istat_provincia = \"data\\codici_istat_provincia.csv\"\n",
    "filename_codici_nazioni = \"data\\codici_nazioni.csv\"\n",
    "filename_day_od = \"data\\day_od.csv\"\n",
    "filename_distinct_user_day = \"data\\distinct_users_day.csv\"\n",
    "filename_distance_to_pd = \"data\\R05_PD.csv\"\n",
    "filename_distance_to_pd_txt = \"data\\R05_PD.txt\"\n",
    "\n",
    "#Creating a list to boost performances of the loops\n",
    "filenames = [filename_codici_istat_comuni, filename_codici_istat_provincia, filename_codici_nazioni,\n",
    "             filename_day_od, filename_distinct_user_day, filename_distance_to_pd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function which returns the encoding of each csv file\n",
    "def check_encoding(file):\n",
    "    #Read the file\n",
    "    with open(file, 'rb') as f:\n",
    "        #Detect the encoding\n",
    "        result = chardet.detect(f.read())\n",
    "\n",
    "    #Return a list of the encodings\n",
    "    return result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Function wich converts the UTF-16 encoded files into ISO-8859-1 encoded files\n",
    "def encoding_converter(files):\n",
    "    for file in files:\n",
    "        #Saving the encoding of each file\n",
    "        encodings = check_encoding(file)\n",
    "\n",
    "        # If the encoding is different to ISO-8859-1 it has to be converted\n",
    "        if encodings == 'ascii' :\n",
    "            # Open the file and saving the content\n",
    "            with codecs.open(file, 'r', 'ascii') as f:\n",
    "                data = f.read()\n",
    "\n",
    "            # Overwrite the file with a new encoding\n",
    "            with io.open(file, 'w', encoding='utf-8') as f:\n",
    "                f.write(data)\n",
    "\n",
    "        if encodings == 'utf-16':\n",
    "            # Open the file and saving the content\n",
    "            with codecs.open(file, 'r', 'utf-16') as f:\n",
    "                data = f.read()\n",
    "\n",
    "            # Overwrite the file with a new encoding\n",
    "            with io.open(file, 'w', encoding='latin1') as f:\n",
    "                f.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Ranking of visitors from foreign countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Ranking of visitors from Italy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Study of the visitors' fluxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Praticamente bisogna controllare tutti i caselli autostradali delle 3 autostrade\n",
    "Sommare tutti i flows attraverso i comuni delle 3 autostrade\n",
    "Potrei plottare in base al casello, per ogni autostrada\n",
    "I codici delle persone intendono l'origine delle persone\n",
    "In realtà è una semplificazione perchè immagino che tutti quelli del nordest abbiano preso l'autostrada A4. Farò così:\n",
    "Suddivido in 4 zone: \n",
    "1. NordEst (A4 To-Mi) ad Est di Padova\n",
    "2. NordOvest (A4 Ts-Ve)\n",
    "3. La parte sinistra dell'Italia prende l'A1 che poi diventa A13\n",
    "4. La parte destra dell'Italia prende direttamente l'A13 (Emilia Marche Abruzzo Molise Puglia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toll_booths(list_of_tolls = [], highway = \"\"):\n",
    "   \n",
    "    if highway == \"A4To-Mi\" :\n",
    "        list_of_tolls.append(\"Torino\", \"Borgo d'Ale\", \"Santhià\", \"Carisio\", \"Balocco\", \"Greggio\", \"Biandrate\", \"Novara\",\n",
    "            \"Mesero\", \"Arluno\", \"Rho\", \"Milano\", \"Monza\", \"Agrate\", \"Cavenago\", \"Trezzo\", \"Capriate\", \"Dalmine\",\n",
    "            \"Bergamo\", \"Seriate\", \"Grumello\", \"Ponte Oglio\", \"Palazzolo\", \"Rovato\", \"Ospitaletto\", \"Castegnato\",\n",
    "            \"Brescia\", \"Desenzano\", \"Sirmione\", \"Peschiera\", \"Sommacampagna\", \"Verona\", \"Soave\", \"Montebello\",\n",
    "            \"Montecchio\", \"Vicenza\", \"Grisignano\")\n",
    "        \n",
    "    elif highway == \"A4Ts-Ve\":\n",
    "        list_of_tolls.append(\"Spinea\", \"Martellago\", \"Preganziol\", \"Meolo\", \"San Donà di Piave\", \"Cessalto\",\n",
    "            \"San Stino di Livenza\", \"Latisana\", \"San Giorgio di Nogaro\", \"Palmanova\", \"Redipuglia\", \"Trieste\")\n",
    "\n",
    "    elif highway == \"A1Ro-Bo\":\n",
    "        list_of_tolls.append(\"Sasso Marconi\", \"Rioveggio\", \"Pian del Voglio\", \"Roncobilaccio\", \"Barberino di Mugello\",\n",
    "            \"Calenzano\", \"Firenze\", \"Incisa\", \"Valdarno\", \"Arezzo\", \"Monte San Savino\", \"Valdichiana\", \"Chiusi\",\n",
    "            \"Fabro\", \"Orvieto\", \"Attigliano\", \"Orte\", \"Magliano Sabina\", \"Ponzano Romano\", \"Guidonia Montecelio\",\n",
    "            \"Valmontone\", \"Colleferro\", \"Anagni\")\n",
    "\n",
    "    elif highway == \"A13Bo-Pd\":\n",
    "        list_of_tolls.append(\"Bologna\", \"Altedo\", \"Ferrara\", \"Occhiobello\", \"Rovigo\", \"Boara\", \"Monselice\", \"Terme Euganee\")\n",
    "    \n",
    "    return list_of_tolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_highway(region, data_users_veneti = None):\n",
    "    #Assumo che le uniche regioni a prendere l'aereo siano le isole\n",
    "    #Assumo che abbiano preso tutti la macchina e nessuno l'aereo o il treno\n",
    "    list_no = [\"Lombardia\", \"Trentino-Alto Adige\", \"Valle d\\'Aosta\", \"Piemonte\", \"Liguria\"]\n",
    "    list_ne = [\"Friuli Venezia Giulia\"]\n",
    "    list_se = [\"Emilia Romagna\", \"Marche\", \"Abruzzo\", \"Molise\", \"Puglia\"]\n",
    "    list_so = [\"Toscana\", \"Umbria\", \"Lazio\", \"Campania\", \"Basilicata\", \"Calabria\"]\n",
    "    if region in list_ne:\n",
    "        return toll_booths(\"A4To-Mi\")\n",
    "    elif region in list_no:\n",
    "        return toll_booths(\"A4Ts-Ve\")\n",
    "    elif region in list_se:\n",
    "        return toll_booths(\"A13Bo-Pd\")\n",
    "    elif region in list_so:\n",
    "        return toll_booths(\"A1Ro-Bo\")\n",
    "    elif region == \"Veneto\":\n",
    "        #Ignoro Padova perchè non prendono l'autostrada\n",
    "        if data_users_veneti['COD_PRO'] == 24 | data_users_veneti['COD_PRO'] == 23: #Vicenza e Verona\n",
    "            return toll_booths(\"A4To-Mi\")\n",
    "        elif data_users_veneti['COD_PRO'] == 25 | data_users_veneti['COD_PRO'] == 26 | data_users_veneti['COD_PRO'] == 27: #Belluno, Treviso e Venezia\n",
    "            return toll_booths(\"A4Ts-Ve\")\n",
    "        elif data_users_veneti['COD_PRO'] == 29: #Rovigo\n",
    "            return toll_booths(\"A13Bo-Pd\")\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_region(data):\n",
    "    regioni = {\n",
    "        'Abruzzo': 13,\n",
    "        'Basilicata': 17,\n",
    "        'Calabria': 18,\n",
    "        'Campania': 15,\n",
    "        'Emilia Romagna': 8,\n",
    "        'Friuli-Venezia Giulia': 6,\n",
    "        'Lazio': 12,\n",
    "        'Liguria': 7,\n",
    "        'Lombardia': 3,\n",
    "        'Marche': 11,\n",
    "        'Molise': 14,\n",
    "        'Piemonte': 1,\n",
    "        'Puglia': 16,\n",
    "        'Sardegna': 20,\n",
    "        'Sicilia': 19,\n",
    "        'Toscana': 9,\n",
    "        'Trentino-Alto Adige': 4,\n",
    "        'Umbria': 10,\n",
    "        'Valle dAosta': 2,\n",
    "        'Veneto': 5}\n",
    "    \n",
    "    # Inizializza una lista per memorizzare i nomi delle regioni\n",
    "    region_names = []\n",
    "    \n",
    "    # Itera attraverso ogni riga del DataFrame\n",
    "    for index, row in data.iterrows():\n",
    "        # Ottieni il codice della regione dalla colonna 'COD_REG'\n",
    "        cod_reg = row['COD_REG']\n",
    "        \n",
    "        # Cerca il nome della regione corrispondente al codice nella colonna 'COD_REG'\n",
    "        for region_name, region_code in regioni.items():\n",
    "            if cod_reg == region_code:\n",
    "                # Aggiungi il nome della regione alla lista\n",
    "                region_names.append(region_name)\n",
    "                break\n",
    "        else:\n",
    "            # Se il codice della regione non è presente nel dizionario 'regioni', aggiungi None\n",
    "            region_names.append(None)\n",
    "    \n",
    "    # Aggiungi la lista dei nomi delle regioni come nuova colonna 'REGIONE' nel DataFrame\n",
    "    data['REGIONE'] = region_names\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visitors_fluxes(file_customers, dow_study=False):\n",
    "    '''\n",
    "    Consider the three main directions:\n",
    "    A13 Roma-Bologna\n",
    "    A4 Torino-Milano\n",
    "    A4 Trieste-Venezia\n",
    "    '''\n",
    "    #Consider the istat province codes\n",
    "    comuni_codes = pd.read_csv(filename_codici_istat_comuni, encoding='latin1', usecols=['COMUNE', 'PRO_COM', 'COD_PRO'])\n",
    "    provinces_codes = pd.read_csv(filename_codici_istat_provincia, encoding='latin1', usecols=['COD_PRO', 'COD_REG'])\n",
    "\n",
    "    codes = pd.merge(comuni_codes, provinces_codes, on='COD_PRO')\n",
    "\n",
    "    codes = codes.drop(['COMUNE'], axis=1)\n",
    "\n",
    "    if not dow_study:\n",
    "        #Now take the data of the customers and see what's their origin and their destination\n",
    "        customers_data = pd.read_csv(file_customers, encoding='latin1', usecols = ['COD_PRO', 'VISITORS'])\n",
    "    else:\n",
    "        customers_data = pd.read_csv(file_customers, encoding='latin1', usecols = ['COD_PRO','VISITORS', 'DOW'])\n",
    "\n",
    "    customers_data = customers_data.groupby('COD_PRO').sum()\n",
    "\n",
    "    customers_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "    user_regions = add_region(codes)\n",
    "\n",
    "    return user_regions\n",
    "    \n",
    "    # #Join between customers_data and province_codes in this way filters the province_codes in which we're not interested\n",
    "    # data = pd.merge(customers_data, codes, on='COD_PRO')\n",
    "\n",
    "    # return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_PRO</th>\n",
       "      <th>PRO_COM</th>\n",
       "      <th>COD_REG</th>\n",
       "      <th>REGIONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>Piemonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>Piemonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>Piemonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>Piemonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>Piemonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950</th>\n",
       "      <td>111</td>\n",
       "      <td>111104</td>\n",
       "      <td>20</td>\n",
       "      <td>Sardegna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7951</th>\n",
       "      <td>111</td>\n",
       "      <td>111105</td>\n",
       "      <td>20</td>\n",
       "      <td>Sardegna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>111</td>\n",
       "      <td>111106</td>\n",
       "      <td>20</td>\n",
       "      <td>Sardegna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>111</td>\n",
       "      <td>111107</td>\n",
       "      <td>20</td>\n",
       "      <td>Sardegna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7954</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7955 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COD_PRO  PRO_COM  COD_REG   REGIONE\n",
       "0           1     1001        1  Piemonte\n",
       "1           1     1002        1  Piemonte\n",
       "2           1     1003        1  Piemonte\n",
       "3           1     1004        1  Piemonte\n",
       "4           1     1005        1  Piemonte\n",
       "...       ...      ...      ...       ...\n",
       "7950      111   111104       20  Sardegna\n",
       "7951      111   111105       20  Sardegna\n",
       "7952      111   111106       20  Sardegna\n",
       "7953      111   111107       20  Sardegna\n",
       "7954     -999     -999     -999      None\n",
       "\n",
       "[7955 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors_fluxes(filename_distinct_user_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visitors(data, range_of_mobility=\"\"):\n",
    "    #Counting the flows ov visitors from every city we're interested (both ways)\n",
    "    data = data.groupby(['PROVINCIA'])[['FLOW']].sum()\n",
    "\n",
    "    far = True\n",
    "\n",
    "    if range_of_mobility == \"nearby\":\n",
    "        far = False\n",
    "\n",
    "    #Saving the informations per highway\n",
    "    A13_Roma_Bologna = far * data.FLOW.loc['Roma'] + data.FLOW.loc['Bologna']\n",
    "    A4_Milano_Torino = data.FLOW.loc['Milano'] + far * data.FLOW.loc['Torino']\n",
    "    A4_Venezia_Trieste = data.FLOW.loc['Venezia'] + data.FLOW.loc['Trieste']\n",
    "\n",
    "    highway = [A13_Roma_Bologna, A4_Milano_Torino, A4_Venezia_Trieste]\n",
    "\n",
    "    #Labels for the plot\n",
    "    highway_labels = [\"A13 Roma-Bologna\", \"A4 Milano-Torino\", \"A4 Venezia-Trieste\"]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(highway_labels, highway, color='skyblue')\n",
    "    plt.xlabel('Highways')\n",
    "    plt.ylabel('Visitors'' flow')\n",
    "    plt.title('Visitors'' flow per highway')\n",
    "    # Set the scale to avoid the exponential notation \n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visitors(visitors_fluxes(filename_day_od))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.b Mid-range mobility\n",
    "Mobility to/from nearby regions, which are Lombardia, Trentino Alto Adige, Friuli Venezia Giulia, Emilia Romagna.\n",
    "QUESTA SOLUZIONE TIENE CONTO DELLE AUTOSTRADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visitors(visitors_fluxes(filename_day_od), \"nearby\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Week flow\n",
    "\n",
    "Consider the provinces located on the three directions that are mostly contributing to the flow of weekend visitors and working daily commuters by performing a more detailed study of the fluxes based on the day of the week. Use the data available to provide what you believe is the best possible answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(data1, data2, label):\n",
    "    #Saving the informations per highway\n",
    "    A13_Roma_Bologna = data1.FLOW.loc['Roma'] + data1.FLOW.loc['Bologna']\n",
    "    A4_Milano_Torino = data1.FLOW.loc['Milano'] + data1.FLOW.loc['Torino']\n",
    "    A4_Venezia_Trieste = data1.FLOW.loc['Venezia'] + data1.FLOW.loc['Trieste']\n",
    "\n",
    "    highway1 = [A13_Roma_Bologna, A4_Milano_Torino, A4_Venezia_Trieste]\n",
    "\n",
    "    #Saving the informations per highway\n",
    "    A13_Roma_Bologna = data2.FLOW.loc['Roma'] + data2.FLOW.loc['Bologna']\n",
    "    A4_Milano_Torino = data2.FLOW.loc['Milano'] + data2.FLOW.loc['Torino']\n",
    "    A4_Venezia_Trieste = data2.FLOW.loc['Venezia'] + data2.FLOW.loc['Trieste']\n",
    "\n",
    "    highway2 = [A13_Roma_Bologna, A4_Milano_Torino, A4_Venezia_Trieste]\n",
    "\n",
    "    #Labels for the plot\n",
    "    highway_labels = [\"A13 Roma-Bologna\", \"A4 Milano-Torino\", \"A4 Venezia-Trieste\"]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    '''\n",
    "    plt.bar(highway_labels, highway, color='skyblue')\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel('Visitors'' flow')\n",
    "    plt.title('Visitors'' flow in ' + label)\n",
    "    # Set the scale to avoid the exponential notation \n",
    "    plt.ticklabel_format(style='plain', axis='y')\n",
    "    plt.tight_layout()\n",
    "    '''\n",
    "    # Plot dei valori\n",
    "    plt.plot(highway_labels, highway1, marker='o')  # 'marker' specifica il tipo di marker per i punti\n",
    "    plt.plot(highway_labels, highway2, marker='x')  # 'marker' specifica il tipo di marker per i punti\n",
    "    plt.xlabel('X')  # Etichetta asse x\n",
    "    plt.ylabel('Y')  # Etichetta asse y\n",
    "    plt.title('Plot tipo funzione dei valori di un DataFrame')  # Titolo del grafico\n",
    "    plt.grid(False)  # Abilita la griglia\n",
    "\n",
    "    plt.show()\n",
    "    #Fare istogramma grouped bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Seleziono i turisti per le tre direzioni, poi li suddivido in weekend e working days\n",
    "'''\n",
    "def dow_visitors_fluxes(data):\n",
    "    data_weekend = data.loc[(data['DOW'] == \"Domenica\") | (data['DOW'] == \"Sabato\")]\n",
    "\n",
    "    data_working_day = data.loc[~data.index.isin(data_weekend.index)]\n",
    "\n",
    "    # #Join between customers_data and province_codes in this way filters the province_codes in which we're not interested\n",
    "    # data_weekend = pd.merge(weekend_flow, data, on='COD_PRO')\n",
    "    # data_working_day = pd.merge(working_day_flow, data, on='COD_PRO')\n",
    "\n",
    "    #Counting the flows ov visitors from every city we're interested (both ways)\n",
    "    data_weekend = data_weekend.groupby(['PROVINCIA'])[['FLOW']].sum()\n",
    "    data_working_day = data_working_day.groupby(['PROVINCIA'])[['FLOW']].sum()\n",
    "\n",
    "    plotter(data_weekend, data_working_day, \"Weekend\")\n",
    "    # plotter(data_working_day, \"Working \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_visitors_fluxes(visitors_fluxes(filename_day_od))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "Plot the distribution of the number of visitors by the distance of the province of origin. Determine which kind of function should be used to describe the distribution.\n",
    "\n",
    "è scritto visitor quindi tolgo i non visitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visitors_distance(province_data):\n",
    "    distances_data = pd.read_csv(province_data, sep=\"\\t\", encoding=\"UTF-8\", usecols=['DEST_PROCOM', 'KM_TOT'])\n",
    "\n",
    "    distances_data.rename(columns={'DEST_PROCOM': 'PRO_COM'}, inplace=True)\n",
    "\n",
    "    distances_data['KM_TOT'] = distances_data['KM_TOT'].str.replace(',','.')\n",
    "    distances_data['KM_TOT'] = pd.to_numeric(distances_data['KM_TOT'])\n",
    "\n",
    "    distances_data = distances_data.groupby(['PRO_COM'])[['KM_TOT']].mean()\n",
    "\n",
    "    customers_data = pd.read_csv(filename_distinct_user_day, encoding=\"latin1\", usecols=['PRO_COM','VISITORS','CUST_CLASS'])\n",
    "\n",
    "    # Escludo Padova\n",
    "    customers_data['PRO_COM'] = np.where(customers_data['PRO_COM'] == 28060.0 , np.nan,\n",
    "                                np.where(customers_data['CUST_CLASS'] != 'visitor', np.nan, customers_data['PRO_COM']))\n",
    "    customers_data.dropna(axis=0, inplace=True)\n",
    "\n",
    "    # Elimina la colonna \"CUST_CLASS\"\n",
    "    customers_data = customers_data.drop('CUST_CLASS', axis=1)\n",
    "\n",
    "    customers_data = customers_data.groupby(['PRO_COM'])[['VISITORS']].sum()\n",
    "\n",
    "    data = pd.merge(distances_data, customers_data, on='PRO_COM')\n",
    "\n",
    "    data = data.sort_values(['VISITORS'], ascending=False)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_visitors_distance(filename_distance_to_pd_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_visitors_distance(data, zoom=1):\n",
    "    # zoom serve a raggruppare le distanze (50 --> raggruppo le distanze ogni 50 km)\n",
    "    # calcolo il range di raggruppamento\n",
    "    period = int(data['KM_TOT'].max() / zoom)\n",
    "    somma_visitatori = []\n",
    "    for n_group in range(1,period+1):\n",
    "        data_grouped = data[data['KM_TOT'].between((n_group-1)*zoom +1 , n_group * zoom)]\n",
    "        somma_visitatori.append(data_grouped['VISITORS'].sum())\n",
    "    \n",
    "    data_to_plot = pd.DataFrame({'DISTANCE_TO_PD': [km * zoom for km in range(0, period)], 'VISITORS': somma_visitatori})\n",
    "    # Impostare l'indice dopo la creazione del DataFrame\n",
    "    data_to_plot.set_index('DISTANCE_TO_PD', inplace=True)\n",
    "\n",
    "    # data_to_plot['KM_TOT'] = np.where(data_to_plot['KM_TOT'] == 0 , np.nan, data_to_plot['KM_TOT'])\n",
    "    # data_to_plot.dropna(axis=0, inplace=True)\n",
    "\n",
    "    # data_nearby = data.loc[(data['KM_TOT'] < 50)]\n",
    "\n",
    "    # data_far = data.loc[~data.index.isin(data_nearby.index)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(data_to_plot['VISITORS'], color='blue', alpha=0.7, bins=20)\n",
    "    plt.xlabel('Distance from Padova (KM)')\n",
    "    plt.ylabel('Number of Visitors')\n",
    "    plt.title('Histogram of Distance from Padova')\n",
    "    plt.grid(True, linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "    #Da riguardare il grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_visitors_distance(data_visitors_distance(filename_distance_to_pd_txt), 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 \n",
    "Assuming an analytic form can be used to describe the trend, create a regression or a fit to estimate the expected number of visitors by the distance of the province of origin and the corresponding uncertainties. Illustrate the difference between the resulting regression with respect to the numbers provided by the Vodafone monitoring, and highlight the five most striking discrepancies from the expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Build linear regression model using TV and Radio as predictors\n",
    "# Split data into predictors X and output Y\n",
    "X = np.array(data['KM_TOT']).reshape(-1,1)\n",
    "y = data['VISITORS']\n",
    "\n",
    "# Initialise and fit model\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(X, y)\n",
    "# plot for residual error\n",
    " \n",
    "   \n",
    "plt.scatter(X,y,color='red')\n",
    "plt.plot(X,model.predict(X),color='green')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.xlabel('Position Level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
